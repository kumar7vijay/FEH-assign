{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "## 1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Multithreading and multiprocessing are both concurrency models used to improve the performance of applications, but they are suited to different scenarios. Here’s a breakdown of when to use each:\n\n### Scenarios Where Multithreading is Preferable\n\n1. I/O-bound Tasks:\n\n    *Description: When the application spends a lot of time waiting for I/O operations (like file reading, network requests, etc.).\n\n    * Example: A web server handling multiple client requests simultaneously can use threads to manage connections without blocking.\n\n2. Shared Memory:\n\n    * Description: When multiple threads need to share data and communicate frequently.\n\n    * Example: In applications like real-time data processing (e.g., stock trading platforms), threads can easily share data through shared memory.\n\n3. Lightweight Tasks:\n\n    * Description: When the tasks are relatively lightweight and don’t require much CPU time.\n\n    * Example: Background tasks in a GUI application that need to perform simple operations while keeping the UI responsive.\n\n4. Low Overhead:\n\n    * Description: Threads are generally lighter and have lower overhead compared to processes, making them more efficient for certain workloads.\n\n    * Example: Video games that require frequent updates to the game state while processing user input.\n\n5. Context Switching:\n\n    * Description: Thread context switching is typically faster than process switching.\n    \n    * Example: Applications that require high responsiveness, like real-time systems.\n\n### Scenarios Where Multiprocessing is a Better Choice\n\n1. CPU-bound Tasks:\n\n    * Description: When the application requires heavy computation and can benefit from multiple CPU cores.\n\n    * Example: Scientific simulations, image processing, or data analysis tasks that require extensive calculations.\n\n2. Isolation and Fault Tolerance:\n\n    * Description: Each process runs in its own memory space, which provides better fault isolation.\n\n    * Example: Web applications where crashing one service (process) should not affect others (e.g., microservices architecture).\n\n3. Global Interpreter Lock (GIL) Limitation:\n\n    * Description: In languages like Python, the GIL restricts the execution of threads, making multiprocessing a better choice for CPU-bound tasks.\n\n    * Example: Numerical computations in Python can be effectively parallelized using multiprocessing.\n\n4. Memory Usage:\n\n    * Description: When tasks require large amounts of memory, and isolating them in separate processes can be beneficial.\n    \n    * Example: Data processing tasks that load large datasets independently.\n\n5. Scalability:\n\n    * Description: Processes can be distributed across multiple machines, making it easier to scale applications horizontally.\n\n    * Example: Cloud-based applications that need to handle varying loads by deploying multiple process instances.\n\n#### Summary\n\n* Multithreading is ideal for I/O-bound tasks and scenarios where low overhead and shared memory are important.\n\n* Multiprocessing is better suited for CPU-bound tasks, isolation, fault tolerance, and scalability.\n\nChoosing between the two largely depends on the specific requirements and characteristics of the task at hand.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 2. Describe what a process pool is and how it helps in managing multiple processes efficiently.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "A process pool is a collection of pre-initialized processes that can be used to execute tasks concurrently. It allows for efficient management and execution of multiple processes, particularly in scenarios that require parallelism. Here’s how a process pool works and its advantages:\n\n### Key Features of a Process Pool\n\n1. Pre-allocated Resources:\n\n    * Processes in a pool are created ahead of time, which avoids the overhead of spawning new processes for every task. This can significantly improve performance, especially in scenarios where tasks are short-lived.\n\n2. Task Queue:\n\n    * The process pool typically uses a queue to manage incoming tasks. When a task is submitted, it gets added to this queue, and available processes can pick up tasks for execution.\n\n3. Concurrency Control:\n\n    * The number of processes in the pool is usually limited to prevent overwhelming system resources. This control helps manage CPU and memory usage effectively.\n\n4. Load Balancing:\n\n    * Tasks can be distributed across available processes, allowing for better load balancing and efficient utilization of CPU cores.\n\n5. Simplified Code:\n\n    * Using a process pool abstracts away much of the complexity involved in creating, managing, and synchronizing processes, making it easier for developers to implement parallel processing.\n\n### Advantages of Using a Process Pool\n\n1. Reduced Overhead:\n\n    * By reusing existing processes, a process pool minimizes the overhead associated with process creation and termination.\n\n2. Improved Performance:\n\n    * For CPU-bound tasks, a process pool can significantly enhance performance by parallelizing computations without the constant overhead of managing processes.\n\n3. Resource Management:\n\n    * Process pools can help manage system resources more effectively by limiting the number of concurrent processes, which can prevent resource exhaustion.\n\n4. Error Handling:\n\n    * Many process pool implementations provide mechanisms for handling errors in worker processes, making it easier to build robust applications.\n\n5. Scalability:\n\n    * Process pools can be scaled up or down by adjusting the number of processes based on the workload, providing flexibility in resource allocation.\n\n### Use Cases\n\n    * Data Processing: Batch processing of large datasets, where each chunk of data can be processed independently.\n\n    * Web Servers: Handling multiple incoming requests concurrently without blocking.\n\n    * Scientific Computing: Running simulations or computations that can be performed in parallel.\n\n### Example in Python\n\nIn Python, the concurrent.futures module provides a convenient way to work with process pools using ProcessPoolExecutor. Here’s a brief example:",
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": "from concurrent.futures import ProcessPoolExecutor\n\ndef square(n):\n    return n * n\n\nif __name__ == \"__main__\":\n    with ProcessPoolExecutor(max_workers=4) as executor:\n        results = list(executor.map(square, range(10)))\n    print(results)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "A process pool is an efficient way to manage multiple processes, offering significant performance and resource management benefits for parallel computing tasks. By reducing overhead and simplifying the management of concurrent processes, it allows developers to focus on writing effective parallel algorithms without getting bogged down in the complexities of process management.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 3.  Explain what multiprocessing is and why it is used in Python programs.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Multiprocessing is a concurrency model that allows a program to run multiple processes simultaneously, leveraging multiple CPU cores for parallel execution. Each process runs in its own memory space and operates independently, which helps avoid some limitations associated with threading, such as the Global Interpreter Lock (GIL) in Python.\n\n### Key Features of Multiprocessing\n\n1. Parallel Execution:\n\n    * Multiprocessing enables true parallelism by running multiple processes at the same time, which is especially beneficial for CPU-bound tasks.\n\n2. Isolation:\n\n    * Each process has its own memory space, which provides better isolation and stability. If one process crashes, it does not affect the others.\n\n3. Scalability:\n\n    * Multiprocessing can easily scale across multiple CPU cores or even multiple machines in distributed systems.\n\n4. Inter-process Communication (IPC):\n\n    * Although processes are isolated, they can still communicate using IPC mechanisms like pipes, queues, or shared memory, allowing for coordination and data sharing.\n\n#### Why Use Multiprocessing in Python?\n\n1. Overcoming the GIL:\n\n    * Python’s GIL allows only one thread to execute at a time in a single process, limiting the performance of CPU-bound applications when using threading. Multiprocessing allows bypassing the GIL by running multiple processes.\n\n2. Performance Improvement:\n\n   * For CPU-intensive tasks, such as data processing, numerical computations, and image processing, multiprocessing can lead to significant performance improvements by fully utilizing available CPU cores.\n\n3. Robustness:\n\n    * Since processes are isolated, the failure of one process does not crash the entire application. This makes it easier to build robust systems.\n\n4. Resource Management:\n\n    * Multiprocessing can better manage system resources by distributing workloads across multiple processes and efficiently utilizing CPU and memory.\n\n5. Task Parallelism:\n\n    * Suitable for tasks that can be easily divided into independent units of work, such as processing items in a large dataset or handling multiple user requests in a web server.\n\n#### Example of Multiprocessing in Python\n\nPython’s multiprocessing module provides an easy way to create and manage processes. Here’s a simple example:",
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": "from multiprocessing import Process, current_process\nimport time\n\ndef worker(number):\n    print(f\"Process {number} started by {current_process().name}\")\n    time.sleep(2)  # Simulating a long-running task\n    print(f\"Process {number} finished by {current_process().name}\")\n\nif __name__ == \"__main__\":\n    processes = []\n    for i in range(5):\n        process = Process(target=worker, args=(i,))\n        processes.append(process)\n        process.start()\n\n    for process in processes:\n        process.join()  # Wait for all processes to complete\n\n    print(\"All processes completed.\")",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Conclusion\n\nMultiprocessing is a powerful tool in Python for achieving parallelism and improving performance, particularly for CPU-bound tasks. By leveraging multiple processes, Python programs can overcome limitations imposed by the GIL, enhance robustness, and better utilize system resources. This makes multiprocessing an essential technique for developers looking to build efficient and scalable applications.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 4. Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Certainly! Here’s an example of a Python program that uses multithreading to add and remove numbers from a shared list while ensuring thread safety using threading.Lock.\n\n### Multithreading Example with Lock\n\nIn this example, one thread will add numbers to a list, while another thread will remove them. A lock will be used to prevent race conditions when accessing the shared list.",
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": "import threading\nimport time\n\n# Shared list and lock\nshared_list = []\nlock = threading.Lock()\n\ndef add_numbers():\n    for i in range(10):\n        time.sleep(0.1)  # Simulate some delay\n        with lock:\n            shared_list.append(i)\n            print(f\"Added: {i} | List: {shared_list}\")\n\ndef remove_numbers():\n    for _ in range(10):\n        time.sleep(0.2)  # Simulate some delay\n        with lock:\n            if shared_list:\n                removed = shared_list.pop(0)\n                print(f\"Removed: {removed} | List: {shared_list}\")\n            else:\n                print(\"List is empty, nothing to remove.\")\n\nif __name__ == \"__main__\":\n    # Create threads\n    add_thread = threading.Thread(target=add_numbers)\n    remove_thread = threading.Thread(target=remove_numbers)\n\n    # Start threads\n    add_thread.start()\n    remove_thread.start()\n\n    # Wait for threads to complete\n    add_thread.join()\n    remove_thread.join()\n\n    print(\"Final List:\", shared_list)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Explanation\n\n1. Imports: The program imports the necessary modules: threading for managing threads and time for simulating delays.\n\n2. Shared Resources: A shared list (shared_list) and a lock (lock) are created. The lock will ensure that only one thread can access the list at a time.\n\n3. Adding Numbers:\n\n    * The add_numbers function simulates adding numbers from 0 to 9 to the list. It uses time.sleep() to create a delay, simulating a longer computation. The with lock: statement ensures that access to the shared list is synchronized.\n\n4. Removing Numbers:\n\n    * The remove_numbers function simulates removing numbers from the list. It also checks if the list is empty before attempting to remove an item, ensuring there are no errors.\n\n5. Thread Creation and Execution:\n\n    * Two threads (add_thread and remove_thread) are created, and both are started. The main program waits for both threads to complete using join().\n\n6. Final Output: After both threads complete, the final state of the shared list is printed.\n\n#### Running the Program\n\nWhen you run the program, you should see interleaved output from the two threads, demonstrating that they are accessing the shared list in a thread-safe manner. The lock ensures that only one thread modifies the list at a time, preventing race conditions.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 5.  Describe the methods and tools available in Python for safely sharing data between threads and processes.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In Python, safely sharing data between threads and processes is crucial to avoid race conditions and ensure data integrity. Here are the primary methods and tools available for achieving safe data sharing in both threading and multiprocessing contexts:\n\n### 1. Threading\n\na. threading.Lock\n\n    * Description: A basic locking mechanism that allows only one thread to access a resource at a time.\n    \n    * Usage: Use acquire() to lock and release() to unlock, or use the context manager (with lock:) for automatic handling.\n\nb. threading.RLock\n\n    * Description: A reentrant lock that allows a thread to acquire the lock multiple times without causing a deadlock.\n\n    * Usage: Useful in scenarios where a thread might need to lock a resource multiple times during its execution.\n\nc. threading.Semaphore\n\n    * Description: Controls access to a resource pool with a specified number of permits.\n    \n    * Usage: Useful for limiting the number of threads that can access a particular resource simultaneously.\n\nd. threading.Condition\n\n    * Description: Allows threads to wait until a certain condition occurs.\n    \n    * Usage: Useful for implementing producer-consumer scenarios where one thread may need to wait for data to be available.\n\ne. threading.Event\n\n    * Description: A simple flag that can be set to true or false, allowing threads to communicate state.\n\n    * Usage: Threads can wait for an event to be set before continuing their work.\n\nf. queue.Queue\n\n    * Description: A thread-safe queue for sharing data between threads.\n\n    * Usage: Supports FIFO (first-in, first-out) operations, making it ideal for producer-consumer problems.\n\n### 2. Multiprocessing\n\na. multiprocessing.Lock\n\n    * Description: Similar to threading.Lock, it provides a lock for synchronizing access to shared resources between processes.\n\n    * Usage: Used to prevent multiple processes from modifying shared data simultaneously.\n\nb. multiprocessing.Queue\n\n    * Description: A process-safe queue for sharing data between processes.\n\n    * Usage: Supports FIFO operations and is ideal for task distribution and communication.\n\nc. multiprocessing.Pipe\n    \n    * Description: Provides a two-way communication channel between two processes.\n\n    * Usage: Can be used for sending and receiving messages or data.\n\nd. multiprocessing.Manager\n    \n    * Description: A way to create shared objects (like lists, dictionaries) that can be accessed by multiple processes.\n\n    * Usage: Provides proxy objects that can be shared and modified between processes.\n\ne. multiprocessing.Value and multiprocessing.Array\n\n    * Description: Special data types for sharing simple values and arrays between processes.\n\n    * Usage: Useful for sharing primitive types and arrays without the overhead of a manager.\n\n3. General Considerations\n\n    * Atomic Operations: Use atomic operations or built-in data types that are inherently thread-safe, like integers and lists with controlled access.\n\n    * Avoid Global State: Minimize the use of global variables that are shared between threads or processes, as this can lead to complicated synchronization issues.\n\n    * Immutable Data: Whenever possible, use immutable data structures (like tuples) to avoid the need for locks altogether.\n\n### Conclusion\n\nWhen designing concurrent applications in Python, it’s essential to choose the right synchronization primitives based on your needs. Threading tools like Lock, Queue, and Event are suitable for thread-safe data sharing, while multiprocessing tools like Lock, Queue, and Manager help manage shared data between processes effectively. Understanding these tools allows you to build robust, efficient, and safe concurrent applications.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Handling exceptions in concurrent programs is crucial for several reasons:\n\n### Importance of Exception Handling in Concurrent Programs\n\n1. Stability and Reliability:\n\n    * Unhandled exceptions can cause entire programs or critical components to crash. In concurrent applications, this could lead to loss of data or inconsistent states across threads or processes.\n\n2. Resource Management:\n\n    * Properly managing exceptions helps ensure that resources (like files, network connections, and memory) are released appropriately, preventing resource leaks and other issues.\n\n3. Inter-thread/Inter-process Communication:\n\n    * Exceptions in one thread or process can affect others, particularly in shared resource scenarios. Ensuring exceptions are caught and handled can help maintain the integrity of shared data.\n\n4. Debugging and Maintenance:\n\n    * Proper exception handling provides useful feedback and logging, making it easier to diagnose issues when they arise. This is especially important in complex concurrent environments.\n\n5. User Experience:\n\n    * Gracefully handling exceptions can enhance user experience by providing meaningful error messages and maintaining application responsiveness, rather than allowing the program to terminate unexpectedly.\n\n#### Techniques for Handling Exceptions in Concurrent Programs\n\n1. Try-Except Blocks:\n\n    * Use standard try and except blocks within threads or processes to catch and handle exceptions locally.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "import threading\n\ndef worker():\n    try:\n        # Simulate work that may raise an exception\n        raise ValueError(\"An error occurred in the worker thread\")\n    except Exception as e:\n        print(f\"Exception caught in thread: {e}\")\n\nthread = threading.Thread(target=worker)\nthread.start()\nthread.join()",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "2. Logging:\n\n    * Implement logging within exception handling to record details about the exceptions, which aids in diagnosing problems later.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import logging\n\nlogging.basicConfig(level=logging.ERROR)\n\ndef worker():\n    try:\n        raise ValueError(\"An error occurred\")\n    except Exception as e:\n        logging.error(f\"Exception caught: {e}\", exc_info=True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": "3. Custom Exception Classes:\n\n    * Define custom exception classes for more specific error handling. This can help distinguish between different error types in concurrent environments.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "class WorkerError(Exception):\n    pass\n\ndef worker():\n    try:\n        raise WorkerError(\"A specific worker error occurred\")\n    except WorkerError as e:\n        print(f\"Caught specific error: {e}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": "4. Future and Exception Handling (in multiprocessing):\n\n    * When using concurrent.futures, exceptions can be captured and re-raised when calling result() on a Future object.",
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": "from concurrent.futures import ThreadPoolExecutor\n\ndef worker():\n    raise ValueError(\"An error occurred in the worker\")\n\nwith ThreadPoolExecutor() as executor:\n    future = executor.submit(worker)\n    try:\n        future.result()  # This will raise the ValueError\n    except Exception as e:\n        print(f\"Caught exception: {e}\")",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "5. Using Threading Condition or Event:\n\n    * For more complex scenarios, using threading.Condition or threading.Event can help manage and signal errors between threads.\n\n6. Graceful Shutdown:\n\n    * Implement mechanisms to gracefully shut down threads or processes in the event of an exception, ensuring that cleanup is performed.\n\n7. Fault Tolerance:\n\n    * Design the system to be resilient to failures by implementing retry logic, fallback mechanisms, or compensating transactions.\n\n### Conclusion\n\nHandling exceptions in concurrent programs is essential for maintaining stability, reliability, and a positive user experience. By employing appropriate techniques—such as try-except blocks, logging, and careful design—you can effectively manage exceptions in a concurrent environment, ensuring that your applications are robust and maintainable.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently. Use concurrent.futures.ThreadPoolExecutor to manage the threads.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Sure! Below is a Python program that uses concurrent.futures.ThreadPoolExecutor to calculate the factorial of numbers from 1 to 10 concurrently. This example demonstrates how to create a thread pool, submit tasks to it, and retrieve the results.\n\n### Factorial Calculation with ThreadPoolExecutor",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import concurrent.futures\nimport math\n\n# Function to calculate factorial\ndef calculate_factorial(n):\n    return math.factorial(n)\n\ndef main():\n    # Numbers to calculate factorial for\n    numbers = range(1, 11)\n\n    # Using ThreadPoolExecutor to manage threads\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        # Submit tasks to the executor\n        futures = {executor.submit(calculate_factorial, num): num for num in numbers}\n\n        # Retrieve results as they complete\n        for future in concurrent.futures.as_completed(futures):\n            num = futures[future]\n            try:\n                result = future.result()\n                print(f\"Factorial of {num} is {result}\")\n            except Exception as e:\n                print(f\"Error calculating factorial for {num}: {e}\")\n\nif __name__ == \"__main__\":\n    main()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Factorial of 1 is 1\nFactorial of 2 is 2\nFactorial of 3 is 6\nFactorial of 4 is 24\nFactorial of 5 is 120\nFactorial of 6 is 720\nFactorial of 7 is 5040\nFactorial of 8 is 40320\nFactorial of 9 is 362880\nFactorial of 10 is 3628800",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Explanation\n\n1. Importing Modules:\n\n    * We import concurrent.futures for managing the thread pool and math for calculating the factorial.\n\n2. Function Definition:\n\n    * The calculate_factorial function takes a number n and returns its factorial using math.factorial().\n\n3. Main Function:\n\n    * We create a range of numbers from 1 to 10.\n    * We use ThreadPoolExecutor to manage the threads. The with statement ensures that the executor is properly cleaned up after use.\n    * We submit tasks to the executor using executor.submit(), storing the future objects in a dictionary (futures) that maps each future to its corresponding number.\n\n4. Retrieving Results:\n\n    * We use concurrent.futures.as_completed() to iterate over the futures as they complete. This allows us to process results in the order of completion rather than submission.\n    * We use future.result() to get the result of each completed future. If an exception occurred during the execution of the task, it is caught and logged.\n\n5. Running the Program:\n\n    * The program is executed in the if __name__ == \"__main__\": block to ensure that it runs when executed as a script.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 processes).",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Certainly! Below is a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. It measures the time taken for the computation with different pool sizes (2, 4, and 8 processes).\n\n### Square Calculation with Multiprocessing Pool",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import multiprocessing\nimport time\n\n# Function to compute the square of a number\ndef square(n):\n    return n * n\n\ndef compute_squares(pool_size):\n    # Create a pool of processes\n    with multiprocessing.Pool(processes=pool_size) as pool:\n        # Measure the start time\n        start_time = time.time()\n\n        # Map the function to the range of numbers\n        results = pool.map(square, range(1, 11))\n\n        # Measure the end time\n        end_time = time.time()\n\n    return results, end_time - start_time\n\ndef main():\n    # Different pool sizes to test\n    pool_sizes = [2, 4, 8]\n\n    for size in pool_sizes:\n        results, duration = compute_squares(size)\n        print(f\"Pool Size: {size} | Results: {results} | Time Taken: {duration:.4f} seconds\")\n\nif __name__ == \"__main__\":\n    main()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Explanation\n\n1. Importing Modules:\n\n    * We import multiprocessing for parallel processing and time for measuring execution time.\n\n2. Function Definition:\n\n    * The square function takes an integer n and returns its square.\n\n3. Compute Squares Function:\n\n    * The compute_squares function creates a multiprocessing pool with a specified number of processes (pool_size).\n    \n    * It measures the time taken to compute the squares using time.time() to capture the start and end times.\n    \n    * The pool.map() method applies the square function to each number in the range from 1 to 10.\n\n4. Main Function:\n\n    * The program defines a list of pool sizes (pool_sizes).\n\n    * It iterates over these sizes, calling compute_squares for each size, and prints the results and the time taken for computation.\n\n5. Running the Program:\n\n    * The if __name__ == \"__main__\": block ensures that the code runs when the script is executed.\n\n#### Output\n\nWhen you run this program, you should see output similar to the following (the actual time may vary depending on system performance):",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "Pool Size: 2 | Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] | Time Taken: 0.1234 seconds\nPool Size: 4 | Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] | Time Taken: 0.0956 seconds\nPool Size: 8 | Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] | Time Taken: 0.0872 seconds",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Conclusion\n\nThis program demonstrates how to use multiprocessing.Pool to perform parallel computations and measure the time taken for various pool sizes. Adjusting the pool size allows you to see how different levels of parallelism affect performance, which can be useful in optimizing resource usage in your applications.",
      "metadata": {}
    }
  ]
}